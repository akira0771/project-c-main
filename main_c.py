import pandas as pd
import io
import numpy as np

# --- Google Drive ãƒ•ã‚¡ã‚¤ãƒ«ID è¨­å®š ---
# æ‹…å½“è€…ã‹ã‚‰å…±æœ‰ã•ã‚ŒãŸIDã‚’åŸ‹ã‚è¾¼ã¿æ¸ˆã¿
YOUTUBE_MASTER_FILE_ID = '1fZntJuEUcpTeXcbR5aGWvVj8WfsAE_Cb'
ATTENDANCE_MASTER_FILE_ID = '1EJeJ5215gngU_7YxlFnj_3kFA4q--Koe'
FINAL_ANALYSIS_FOLDER_ID = '1w8pmCqX2TxJHfearx1XBmm4XRAXsV8We'

# âš ï¸ ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ã®åˆ—åã‚’è¨­å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡å®šã«ã‚ˆã‚Š 'no' ã‚’ä½¿ç”¨ï¼‰
YOUTUBE_RANKING_COLUMN = 'no' 

# Google Driveæ“ä½œã®ãŸã‚ã«PyDrive2ã¨èªè¨¼é–¢é€£ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive

# --- Google Drive èªè¨¼ã¨ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œé–¢æ•° ---

def authenticate_drive():
    """GitHub Actionsç’°å¢ƒã§Secretsã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸèªè¨¼æƒ…å ±ã§èªè¨¼ã‚’è¡Œã†"""
    gauth = GoogleAuth()
    gauth.DEFAULT_SETTINGS['client_config_file'] = 'credentials.json' 
    gauth.LocalWebserverAuth = lambda: None 
    gauth.ServiceAuth()
    return GoogleDrive(gauth)

def download_csv_to_dataframe(drive_service, file_id):
    """ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’æŒ‡å®šã—ã¦CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€Pandas DataFrameã¨ã—ã¦è¿”ã™"""
    try:
        file = drive_service.CreateFile({'id': file_id})
        downloaded_content = file.GetContentString(mimetype='text/csv')
        df = pd.read_csv(io.StringIO(downloaded_content), parse_dates=['date'])
        return df
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ID {file_id} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def download_existing_movie_csv(drive_service, folder_id, file_name):
    """æ—¢å­˜ã®æ˜ ç”»åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—DataFrameã¨ã—ã¦è¿”ã™ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneï¼‰"""
    try:
        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã§æ¤œç´¢
        file_list = drive_service.ListFile({
            'q': f"'{folder_id}' in parents and title='{file_name}' and trashed=false"
        }).GetList()

        if file_list:
            file = file_list[0]
            downloaded_content = file.GetContentString(mimetype='text/csv')
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®'æ—¥ä»˜'ã‚«ãƒ©ãƒ ã‚’æ—¥ä»˜å‹ã¨ã—ã¦èª­ã¿è¾¼ã¿ã¾ã™
            df = pd.read_csv(io.StringIO(downloaded_content), parse_dates=['æ—¥ä»˜'])
            print(f"æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
            return df
        else:
            return None 
    except Exception as e:
        print(f"è­¦å‘Š: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def upload_dataframe_as_csv(drive_service, df, folder_id, file_name):
    """DataFrameã‚’CSVã¨ã—ã¦æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/æ›´æ–°ã™ã‚‹"""
    try:
        output = io.StringIO()
        df.to_csv(output, index=False)
        output_content = output.getvalue()

        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢
        file_list = drive_service.ListFile({
            'q': f"'{folder_id}' in parents and title='{file_name}' and trashed=false"
        }).GetList()

        if file_list:
            file = file_list[0]
        else:
            file = drive_service.CreateFile({
                'title': file_name,
                'parents': [{'id': folder_id}],
                'mimeType': 'text/csv'
            })

        file.SetContentString(output_content)
        file.Upload()
        print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ: {file_name}")

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {file_name} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def get_or_create_folder_id(drive_service, parent_folder_id, folder_name):
    """æŒ‡å®šã•ã‚ŒãŸè¦ªãƒ•ã‚©ãƒ«ãƒ€å†…ã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢ã—ã€ãªã‘ã‚Œã°ä½œæˆã—ã¦IDã‚’è¿”ã™"""
    # ãƒ•ã‚©ãƒ«ãƒ€ã®æ¤œç´¢ã‚¯ã‚¨ãƒª
    query = f"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and '{parent_folder_id}' in parents and trashed=false"
    file_list = drive_service.ListFile({'q': query}).GetList()

    if file_list:
        folder_id = file_list[0]['id']
        print(f"æ—¢å­˜ã®ãƒ•ã‚©ãƒ«ãƒ€ '{folder_name}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ID: {folder_id}")
        return folder_id
    else:
        # ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ
        folder_metadata = {
            'title': folder_name,
            'mimeType': 'application/vnd.google-apps.folder',
            'parents': [{'id': parent_folder_id}]
        }
        folder = drive_service.CreateFile(folder_metadata)
        folder.Upload()
        folder_id = folder['id']
        print(f"æ–°è¦ãƒ•ã‚©ãƒ«ãƒ€ '{folder_name}' ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ID: {folder_id}")
        return folder_id


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ ---

def main_processor():
    drive_service = authenticate_drive()
    if drive_service is None:
        print("è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: Google Driveã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return

    # 1. ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»èª­ã¿è¾¼ã¿
    df_youtube = download_csv_to_dataframe(drive_service, YOUTUBE_MASTER_FILE_ID)
    df_attendance = download_csv_to_dataframe(drive_service, ATTENDANCE_MASTER_FILE_ID)

    if df_youtube is None or df_attendance is None:
        print("è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
        return

    # 2. ãƒ‡ãƒ¼ã‚¿ã®çµåˆã¨å¿…è¦ãªåˆ—ã®æŠ½å‡º/åŠ å·¥
    
    # 'no'åˆ—ã‚’å«ã‚ã¦YouTubeãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠ½å‡º
    df_youtube = df_youtube[['date', 'movie_title', YOUTUBE_RANKING_COLUMN, 'daily_new_views']]
    df_youtube = df_youtube.rename(columns={'daily_new_views': 'å‹•ç”»ã®å†ç”Ÿæ•°'})
    
    # 'date'ã¨'movie_title'ã‚’ã‚­ãƒ¼ã«inner joinï¼ˆBãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ˜ ç”»æƒ…å ±ã‚’æ¤œç´¢ãƒ»æŠ½å‡ºï¼‰
    combined_df = pd.merge(
        df_youtube,
        df_attendance,
        on=['date', 'movie_title'],
        how='inner'
    )
    
    if len(combined_df) == 0:
        print("è­¦å‘Š: çµåˆãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ0ä»¶ã§ã™ã€‚æ—¥æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸¡æ–¹ã«å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # æœ€çµ‚çš„ãªå‡ºåŠ›åˆ—ã‚’é¸æŠã—ã€åˆ—åã‚’æ—¥æœ¬èªã«çµ±ä¸€
    final_combined_df = combined_df[[
        'movie_title', 
        'daily_sales_or_attendance', 
        'å‹•ç”»ã®å†ç”Ÿæ•°', 
        'date',
        YOUTUBE_RANKING_COLUMN # 'no'åˆ—ã‚’å«ã‚ã‚‹
    ]].rename(columns={
        'movie_title': 'æ˜ ç”»å',
        'daily_sales_or_attendance': 'èˆˆè¡Œåå…¥_å‹•å“¡æ•°',
        'date': 'æ—¥ä»˜',
        YOUTUBE_RANKING_COLUMN: 'ãƒŠãƒ³ãƒãƒªãƒ³ã‚°' # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯æ—¥æœ¬èªå 'ãƒŠãƒ³ãƒãƒªãƒ³ã‚°' ã‚’ä½¿ç”¨
    })
    
    # 'ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'åˆ—ã‚’æ•´æ•°å‹ã«å¤‰æ›ï¼ˆãƒ•ã‚©ãƒ«ãƒ€åã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã€å°æ•°ç‚¹ä»¥ä¸‹ã‚’å‰Šé™¤ï¼‰
    final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'] = final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'].astype(str).str.replace(r'\..*$', '', regex=True).astype(int)

    print(f"âœ… ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®çµåˆã¨åŠ å·¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(final_combined_df)}")

    # 3. ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã¨ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ï¼ˆ2æ®µéšã®ãƒ«ãƒ¼ãƒ—ï¼‰
    
    ranking_ids = sorted(final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'].unique())

    for ranking_id in ranking_ids:
        # 3-1. ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ«ãƒ€ã®IDã‚’å–å¾— (å­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆ)
        ranking_folder_id = get_or_create_folder_id(
            drive_service, 
            FINAL_ANALYSIS_FOLDER_ID, 
            str(ranking_id) # ãƒ•ã‚©ãƒ«ãƒ€åã¯æ–‡å­—åˆ—
        )
        
        # ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ã§çµã‚Šè¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿
        df_ranking_data = final_combined_df[final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'] == ranking_id].copy()

        # 3-2. ãƒŠãƒ³ãƒãƒªãƒ³ã‚°å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã•ã‚‰ã«æ˜ ç”»åã§ãƒ«ãƒ¼ãƒ—
        movie_titles_in_ranking = df_ranking_data['æ˜ ç”»å'].unique()
        
        for movie in movie_titles_in_ranking:
            # æ˜ ç”»ã”ã¨ã®æ–°ã—ã„æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿
            df_new_data = df_ranking_data[df_ranking_data['æ˜ ç”»å'] == movie].copy()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®å®šç¾© (ä¾‹: 'æ˜ ç”»A.csv')
            output_file_name = f"{movie}.csv"
            
            # æ—¢å­˜ã®æ˜ ç”»åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰)
            df_existing = download_existing_movie_csv(drive_service, ranking_folder_id, output_file_name)
            
            if df_existing is not None and not df_existing.empty:
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨æ–°ã—ã„æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                df_updated = pd.concat([df_existing, df_new_data], ignore_index=True)
                
                # é‡è¤‡è¡Œã®å‰Šé™¤ï¼ˆæ—¥ä»˜ã¨æ˜ ç”»åã§ä¸Šæ›¸ãï¼‰
                df_updated.drop_duplicates(
                    subset=['æ˜ ç”»å', 'æ—¥ä»˜'], 
                    keep='last', 
                    inplace=True
                )
                print(f"ğŸ“ˆ {output_file_name} ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df_updated)}")
            else:
                df_updated = df_new_data
                print(f"ğŸš€ {output_file_name} ã‚’æ–°è¦ä½œæˆã—ã¾ã™ã€‚")

            # 4. Google Driveã®ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            upload_dataframe_as_csv(
                drive_service, 
                df_updated, 
                ranking_folder_id, 
                output_file_name
            )
        
    print("\nâœ… å…¨ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


if __name__ == '__main__':
    main_processor()
