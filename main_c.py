import pandas as pd
import io
import numpy as np
import sys 
import logging # ãƒ­ã‚®ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from datetime import datetime # æ—¥æ™‚å–å¾—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive

# --- Google Drive ãƒ•ã‚¡ã‚¤ãƒ«ID è¨­å®š ---
YOUTUBE_MASTER_FILE_ID = '1fZntJuEUcpTeXcbR5aGWvVj8WfsAE_Cb'
ATTENDANCE_MASTER_FILE_ID = '1EJeJ5215gngU_7YxlFnj_3kFA4q--Koe'
FINAL_ANALYSIS_FOLDER_ID = '1w8pmCqX2TxJHfearx1XBmm4XRAXsV8We'

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
LOG_FILE_NAME = 'process_error_log.txt'
YOUTUBE_RANKING_COLUMN = 'no' 

# --- ãƒ­ã‚®ãƒ³ã‚°é–¢æ•° ---
def setup_logging():
    """ãƒ­ã‚®ãƒ³ã‚°ã‚’è¨­å®šã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹"""
    logging.basicConfig(
        filename=LOG_FILE_NAME,
        level=logging.ERROR,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã®ãƒãƒ³ãƒ‰ãƒ©ã‚’è¿½åŠ 
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.ERROR)
    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    logging.getLogger().addHandler(console_handler)

def log_error(message, e):
    """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚è¡¨ç¤ºã™ã‚‹"""
    error_message = f"{message}: {e}"
    logging.error(error_message)
    print(f"âŒ ãƒ­ã‚°è¨˜éŒ²æ¸ˆã¿ã‚¨ãƒ©ãƒ¼: {error_message}")

# --- Google Drive èªè¨¼ã¨ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œé–¢æ•° ---

def upload_log_file(drive_service, folder_id):
    """ç”Ÿæˆã•ã‚ŒãŸãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/æ›´æ–°ã™ã‚‹"""
    try:
        with open(LOG_FILE_NAME, 'r') as f:
            log_content = f.read()

        # æ—¢å­˜ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        file_list = drive_service.ListFile({
            'q': f"'{folder_id}' in parents and title='{LOG_FILE_NAME}' and trashed=false"
        }).GetList()

        if file_list:
            file = file_list[0]
        else:
            file = drive_service.CreateFile({
                'title': LOG_FILE_NAME,
                'parents': [{'id': folder_id}],
                'mimeType': 'text/plain'
            })

        file.SetContentString(log_content)
        file.Upload()
        print(f"âœ… ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« '{LOG_FILE_NAME}' ã‚’Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/æ›´æ–°ã—ã¾ã—ãŸã€‚")

    except FileNotFoundError:
        print(f"âš ï¸ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« '{LOG_FILE_NAME}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    except Exception as e:
        log_error(f"è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®Google Driveã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ", e)

def authenticate_drive():
    """GitHub Actionsç’°å¢ƒã§Secretsã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸèªè¨¼æƒ…å ±ã§èªè¨¼ã‚’è¡Œã†"""
    try:
        gauth = GoogleAuth()
        gauth.DEFAULT_SETTINGS['client_config_file'] = 'credentials.json' 
        gauth.LocalWebserverAuth = lambda: None 
        gauth.ServiceAuth()
        return GoogleDrive(gauth)
    except Exception as e:
        log_error("Google Driveã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ", e)
        return None

def download_csv_to_dataframe(drive_service, file_id):
    """ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’æŒ‡å®šã—ã¦CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€Pandas DataFrameã¨ã—ã¦è¿”ã™"""
    try:
        file = drive_service.CreateFile({'id': file_id})
        downloaded_content = file.GetContentString(mimetype='text/csv')
        df = pd.read_csv(io.StringIO(downloaded_content), parse_dates=['date'])
        return df
    except Exception as e:
        log_error(f"ãƒ•ã‚¡ã‚¤ãƒ«ID {file_id} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ", e)
        return None

def download_existing_movie_csv(drive_service, folder_id, file_name):
    """æ—¢å­˜ã®æ˜ ç”»åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—DataFrameã¨ã—ã¦è¿”ã™ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneï¼‰"""
    try:
        # ... (æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—)
        file_list = drive_service.ListFile({
            'q': f"'{folder_id}' in parents and title='{file_name}' and trashed=false"
        }).GetList()

        if file_list:
            file = file_list[0]
            downloaded_content = file.GetContentString(mimetype='text/csv')
            df = pd.read_csv(io.StringIO(downloaded_content), parse_dates=['æ—¥ä»˜'])
            print(f"æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
            return df
        else:
            return None 
    except Exception as e:
        log_error(f"æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", e)
        return None

def upload_dataframe_as_csv(drive_service, df, folder_id, file_name):
    """DataFrameã‚’CSVã¨ã—ã¦æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/æ›´æ–°ã™ã‚‹"""
    try:
        output = io.StringIO()
        df.to_csv(output, index=False)
        output_content = output.getvalue()

        # ... (æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ãƒ»ä½œæˆãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—)
        file_list = drive_service.ListFile({
            'q': f"'{folder_id}' in parents and title='{file_name}' and trashed=false"
        }).GetList()

        if file_list:
            file = file_list[0]
        else:
            file = drive_service.CreateFile({
                'title': file_name,
                'parents': [{'id': folder_id}],
                'mimeType': 'text/csv'
            })

        file.SetContentString(output_content)
        file.Upload()
        print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ: {file_name}")

    except Exception as e:
        log_error(f"{file_name} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ", e)

def get_or_create_folder_id(drive_service, parent_folder_id, folder_name):
    """æŒ‡å®šã•ã‚ŒãŸè¦ªãƒ•ã‚©ãƒ«ãƒ€å†…ã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢ã—ã€ãªã‘ã‚Œã°ä½œæˆã—ã¦IDã‚’è¿”ã™"""
    try:
        # ... (ãƒ•ã‚©ãƒ«ãƒ€æ¤œç´¢ãƒ»ä½œæˆãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—)
        query = f"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and '{parent_folder_id}' in parents and trashed=false"
        file_list = drive_service.ListFile({'q': query}).GetList()

        if file_list:
            folder_id = file_list[0]['id']
            print(f"æ—¢å­˜ã®ãƒ•ã‚©ãƒ«ãƒ€ '{folder_name}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ID: {folder_id}")
            return folder_id
        else:
            folder_metadata = {
                'title': folder_name,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [{'id': parent_folder_id}]
            }
            folder = drive_service.CreateFile(folder_metadata)
            folder.Upload()
            folder_id = folder['id']
            print(f"æ–°è¦ãƒ•ã‚©ãƒ«ãƒ€ '{folder_name}' ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ID: {folder_id}")
            return folder_id
    except Exception as e:
        log_error(f"ãƒ•ã‚©ãƒ«ãƒ€ '{folder_name}' ã®å–å¾—ã¾ãŸã¯ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ", e)
        return None


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ ---

def main_processor():
    # ãƒ­ã‚°è¨­å®šã‚’æœ€åˆã«å®Ÿè¡Œ
    setup_logging()
    
    drive_service = authenticate_drive()
    if drive_service is None:
        sys.exit(1) # èªè¨¼å¤±æ•—æ™‚ã¯å³æ™‚çµ‚äº†ï¼ˆãƒ­ã‚°ã¯authenticate_driveã§è¨˜éŒ²æ¸ˆã¿ï¼‰

    # 1. ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»èª­ã¿è¾¼ã¿
    df_youtube = download_csv_to_dataframe(drive_service, YOUTUBE_MASTER_FILE_ID)
    df_attendance = download_csv_to_dataframe(drive_service, ATTENDANCE_MASTER_FILE_ID)

    if df_youtube is None or df_attendance is None:
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã¯ãƒ­ã‚°è¨˜éŒ²æ¸ˆã¿ã®ãŸã‚ã€ãã®ã¾ã¾çµ‚äº†
        print("è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
        upload_log_file(drive_service, FINAL_ANALYSIS_FOLDER_ID) # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        sys.exit(1)

    # 2. ãƒ‡ãƒ¼ã‚¿ã®çµåˆã¨å¿…è¦ãªåˆ—ã®æŠ½å‡º/åŠ å·¥
    try:
        df_youtube = df_youtube[['date', 'movie_title', YOUTUBE_RANKING_COLUMN, 'daily_new_views']]
        df_youtube = df_youtube.rename(columns={'daily_new_views': 'å‹•ç”»ã®å†ç”Ÿæ•°'})
        
        combined_df = pd.merge(
            df_youtube,
            df_attendance,
            on=['date', 'movie_title'],
            how='inner'
        )
        
        if len(combined_df) == 0:
            print("è­¦å‘Š: çµåˆãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ0ä»¶ã§ã™ã€‚æ—¥æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸¡æ–¹ã«å­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # ... (ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿åŠ å·¥ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—)
        final_combined_df = combined_df[[
            'movie_title', 
            'daily_sales_or_attendance', 
            'å‹•ç”»ã®å†ç”Ÿæ•°', 
            'date',
            YOUTUBE_RANKING_COLUMN 
        ]].rename(columns={
            'movie_title': 'æ˜ ç”»å',
            'daily_sales_or_attendance': 'èˆˆè¡Œåå…¥_å‹•å“¡æ•°',
            'date': 'æ—¥ä»˜',
            YOUTUBE_RANKING_COLUMN: 'ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'
        })
        
        final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'] = final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'].astype(str).str.replace(r'\..*$', '', regex=True).astype(int)

        print(f"âœ… ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®çµåˆã¨åŠ å·¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(final_combined_df)}")

    except Exception as e:
        log_error("ãƒ‡ãƒ¼ã‚¿çµåˆ/åŠ å·¥ãƒ•ã‚§ãƒ¼ã‚ºã§è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", e)
        upload_log_file(drive_service, FINAL_ANALYSIS_FOLDER_ID)
        sys.exit(1)

    # 3. ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆã¨ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
    ranking_ids = sorted(final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'].unique())

    for ranking_id in ranking_ids:
        # ãƒ•ã‚©ãƒ«ãƒ€æ“ä½œã¯get_or_create_folder_idå†…ã§ãƒ­ã‚®ãƒ³ã‚°ã•ã‚Œã‚‹
        ranking_folder_id = get_or_create_folder_id(
            drive_service, 
            FINAL_ANALYSIS_FOLDER_ID, 
            str(ranking_id)
        )
        
        if ranking_folder_id is None:
             continue
        
        df_ranking_data = final_combined_df[final_combined_df['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°'] == ranking_id].copy()

        for movie in df_ranking_data['æ˜ ç”»å'].unique():
            df_new_data = df_ranking_data[df_ranking_data['æ˜ ç”»å'] == movie].copy()
            output_file_name = f"{movie}.csv"
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ“ä½œã¯download_existing_movie_csvå†…ã§ãƒ­ã‚®ãƒ³ã‚°ã•ã‚Œã‚‹
            df_existing = download_existing_movie_csv(drive_service, ranking_folder_id, output_file_name)
            
            try:
                if df_existing is not None and not df_existing.empty:
                    df_updated = pd.concat([df_existing, df_new_data], ignore_index=True)
                    df_updated.drop_duplicates(subset=['æ˜ ç”»å', 'æ—¥ä»˜'], keep='last', inplace=True)
                    print(f"ğŸ“ˆ {output_file_name} ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df_updated)}")
                else:
                    df_updated = df_new_data
                    print(f"ğŸš€ {output_file_name} ã‚’æ–°è¦ä½œæˆã—ã¾ã™ã€‚")

            except Exception as e:
                log_error(f"æ˜ ç”» '{movie}' ã®ãƒ‡ãƒ¼ã‚¿çµåˆãƒ­ã‚¸ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", e)
                continue # ã“ã®æ˜ ç”»ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€æ¬¡ã®æ˜ ç”»ã«é€²ã‚€

            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ“ä½œã¯upload_dataframe_as_csvå†…ã§ãƒ­ã‚®ãƒ³ã‚°ã•ã‚Œã‚‹
            df_updated = df_updated.sort_values(by=['ãƒŠãƒ³ãƒãƒªãƒ³ã‚°', 'æ—¥ä»˜'])
            upload_dataframe_as_csv(
                drive_service, 
                df_updated, 
                ranking_folder_id, 
                output_file_name
            )
        
    print("\nâœ… å…¨ãƒŠãƒ³ãƒãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    
    # æœ€å¾Œã«ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    upload_log_file(drive_service, FINAL_ANALYSIS_FOLDER_ID)


if __name__ == '__main__':
    main_processor()
